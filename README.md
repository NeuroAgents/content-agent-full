# Микросервис обработки контента с Gemini API

Микросервис для обработки, переписывания и перевода статей с использованием Google Gemini API.

## Описание

Данный микросервис выполняет следующие функции:

1. Загрузка необработанных статей из базы данных Supabase
2. Очистка HTML-контента с использованием BeautifulSoup
3. Переписывание контента с улучшением качества и стиля через Gemini API
4. Перевод контента с английского на русский язык через Gemini API
5. Сохранение обновленного контента в базе данных

## Зависимости

- Python 3.10+
- supabase-py
- google-generativeai
- beautifulsoup4
- python-dotenv

## Установка

1. Клонировать репозиторий:

```bash
git clone https://github.com/NeuroAgents/content-agent-full.git
cd content-agent-full
```

2. Создать и активировать виртуальное окружение:

```bash
python -m venv venv
source venv/bin/activate  # На Windows: venv\Scripts\activate
```

3. Установить зависимости:

```bash
pip install -r requirements.txt
```

4. Создать `.env` файл на основе `.env.example`:

```bash
cp .env.example .env
```

5. Заполнить `.env` файл необходимыми данными:

```
SUPABASE_URL=ваш_supabase_url
SUPABASE_KEY=ваш_supabase_key
GEMINI_API_KEY=ваш_gemini_api_key
LOG_FILE=logs/content_processor.log
```

## Использование

### Ручной запуск

Для ручного запуска обработчика контента выполните:

```bash
python content_processor_direct.py --limit 5 --hours 24
```

Параметры:

- `--limit`: количество статей для обработки (по умолчанию 5)
- `--hours`: временное окно для выбора статей в часах (по умолчанию 24)
- `--dry-run`: режим тестирования без внесения изменений в базу данных

### Автоматический запуск

Для автоматического запуска с помощью скрипта:

```bash
./run_content_processor.sh
```

### Настройка cron для регулярного запуска

1. Отредактируйте файл `crontab.txt`, укажите правильный путь к директории проекта:

```
# Запуск обработчика контента каждые 2 часа
0 */2 * * * cd /путь/к/проекту && ./run_content_processor.sh >> /путь/к/проекту/logs/cron.log 2>&1
```

2. Установите cron задание:

```bash
crontab crontab.txt
```

## Структура проекта

- `content_processor_direct.py` - основной скрипт обработки контента
- `run_content_processor.sh` - скрипт для запуска обработчика контента
- `crontab.txt` - настройки планировщика cron
- `.env` - файл с переменными окружения (не включен в репозиторий)
- `.env.example` - пример файла с переменными окружения

## Логирование

Логи работы обработчика контента сохраняются в файле, указанном в переменной окружения `LOG_FILE`. По умолчанию это `logs/content_processor.log`.

## Обработка ошибок

Скрипт включает механизм повторных попыток с экспоненциальной задержкой для обработки ошибок, связанных с превышением квоты API Gemini. Если возникают другие ошибки, они записываются в лог-файл.
